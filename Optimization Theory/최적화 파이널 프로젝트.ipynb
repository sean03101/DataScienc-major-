{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RF4BBFvVvA7h"
   },
   "source": [
    "# Abstract\n",
    "\n",
    "\n",
    "In this AI project, we propose a deep learning model that predicts the exact target location through the Time Difference Of Arrival for each location measurement sensor in an environment where there are indoor obstacles and errors. The deep learning model we envisioned proceeds in the following order. Errors that may occur due to internal obstacles are reflected in the TDOA measurement value for each sensor. TDOA data with errors reflected is converted into TDOA images. A TDOA image consists of the probabilities of a hyperbola graph passing through each image grid. Train a CNN model with fully connected layers to estimate target positions via backpropagation by accumulating and processing TDOA images as input data. We compared the performance of a model using CNN and a simple learning model and examined where our results can be applied in real life.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXdtrhr-vj-J"
   },
   "source": [
    "\n",
    "# Introduction \n",
    "\n",
    "\n",
    "With the development of IT technology, unmanned systems are gradually being used in many fields. In particular, in unmanned stores for example Amazon Go, when a customer puts items in a shopping cart and goes straight to the exit without a checkout process, the product that are purchased are identified and payment is automatically made. This technology is possible because many sensors and cameras in the store can determine what products a customer has in their shopping cart.\n",
    "\n",
    "However, these sensors and cameras are expensive to purchase and for operate. In order to reduce cost, Recent preliminary studies have tried to obtain accurate TDOA through several algorithms, especially deep learning.\n",
    "\n",
    "Several studies that use deep-learning, TDOA for location , method simply inferred the correct TDOA value and tracked the location using the hyperbolic equation, and did not use deep learning for the entire process. In addition, the method of estimating the position through TDOA is essential to find the intersection of the hyperbolic equations, but this process needs a lot of computer resources to solve these complex nonlinear equations. \n",
    "\n",
    "Therefore, to solve these problems, we will build a deep lear:ning model that estimates the exact coordinates of the target by using the TDOA values extracted from the rough space. In particular, we will build a CNN model by converting each TDOA measurement into a TDOA image. We expect that it will be possible to accurately and quickly determine the location of the target even in complex spaces such as unmanned convenience stores and indoor gyms.\n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TMMkuAUOBCZzD8MhjaiZyF6aXK7ZXfKB' width=\"400\"> \n",
    "<img src='https://drive.google.com/uc?id=1TMdM__fzPziQVLQ3xDkhUgrxpKAwxh3z' width=\"400\">\n",
    "\n",
    "<Fig1. Amazon Go camera and sensors> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<Fig2. Estimate target coordinate by TDOA>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUVEqBIcVE_P"
   },
   "source": [
    "# Simulation architecture\n",
    "1. Generate true target coordinate - ($y$)\n",
    "2. Generate target coordinate from device - ($\\hat{y}$)\n",
    "3. Generate TOA data and apply noise and Frasnel zone distance and calculate TDOA\n",
    "4. Convert TDOA data into TDOA image\n",
    "5. Make CNN model\n",
    "6. Create Output \n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1iSyJAdws-qDoLC8H5hq-zk-Gy60onsg0' width=\"1200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhWvrceLBuT7"
   },
   "source": [
    "# Our codes\n",
    "\n",
    "## Implement packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q80z3tYQ-v-N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPWmZEXbCzRw"
   },
   "source": [
    "## Hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ziG6hh4Cyuv"
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# fix me\n",
    "# Parameters for CNNs\n",
    "CNN1_inputchannel = 3\n",
    "CNN1_outchannel = 128 \n",
    "CNN1_kernal = 2\n",
    "CNN1_stride = 1\n",
    "\n",
    "CNN2_outchannel = 128\n",
    "CNN2_kernal = 2\n",
    "CNN2_stride = 1\n",
    "\n",
    "CNN3_outchannel = 256\n",
    "CNN3_kernal = 2\n",
    "CNN3_stride = 1\n",
    "\n",
    "Pool_kernal = 2 # max pooling\n",
    "Pool_stride = 2\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 10\n",
    "\n",
    "sensor_ref = [0,0]\n",
    "sensor1 = [25,0]\n",
    "sensor2 = [0,25]\n",
    "sensor3 = [25,25]\n",
    "\n",
    "world_size_x = 25\n",
    "world_size_y = 25\n",
    "grid_size = 0.25\n",
    "\n",
    "epsilon = 0.01\n",
    "probability_gap = 10\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tqBSlPEiE9F"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kCuZ32x4LgJ"
   },
   "source": [
    "# Overall procsees for creating train dataset\n",
    "\n",
    "1. Create arbitraely X and Y target data between 0~25\n",
    "    + Target data is made!\n",
    "2. Apply random noise to arbitraely generated target data (hat data)\n",
    "    + this is hat data that measured by device\n",
    "    + X target data with noise is X_hat, Y target data with noise is Y_hat\n",
    "3. Create distance between each sensor and hat data\n",
    "\n",
    "4. Apply environmental error\n",
    "\n",
    "5. Create TDOA between reference sensor and each sensor\n",
    "\n",
    "6. Change TDOA to TDOA image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwhgNJrW_DdI"
   },
   "source": [
    "### Create arbitraely X and Y target data between 0~25\n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TMCu_GfO0clZAngFK1pWDkqDCh19s_KH' width=\"400\">\n",
    "\n",
    "\n",
    "+ Sensor_ref = [0,0]\n",
    "+ Sensor_1 = [25,0]\n",
    "+ Sensor_2 = [0,25]\n",
    "+ Sensor_3 = [25,25]\n",
    "\n",
    "+ Target = [x,y] (0 <= x,y <= 25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaX3b-Sf-7sV"
   },
   "outputs": [],
   "source": [
    "MC_N = 10**4   # Number of total simulation\n",
    "MC_N = int(MC_N * 2)\n",
    "\n",
    "size_x = 25   # X axis size\n",
    "size_y = 25   # Y axis size\n",
    "\n",
    "X_x_list = np.random.rand(MC_N,1) * size_x    # Target X axis data that generated randomly between 0~25\n",
    "X_x_list = X_x_list.flatten().tolist()\n",
    "X_y_list = np.random.rand(MC_N,1) * size_y    # Target Y axis data that generated randomly between 0~25\n",
    "X_y_list = X_y_list.flatten().tolist()\n",
    "\n",
    "sensor_ref_x_list = [0] * MC_N                      #sensor ref x coordinate\n",
    "sensor_ref_y_list = [0] * MC_N                      #sensor ref  y coordinate\n",
    "sensor_one_x_list = [size_x] * MC_N                 #sensor 1 x coordinate\n",
    "sensor_one_y_list = [0] * MC_N                      #sensor 1 y coordinate\n",
    "sensor_two_x_list = [0] * MC_N                      #sensor 2 x coordinate\n",
    "sensor_two_y_list = [size_y] * MC_N                 #sensor 2 y coordinate\n",
    "sensor_three_x_list = [size_x] * MC_N                #sensor 3 x coordinate\n",
    "sensor_three_y_list = [size_y] * MC_N                #sensor 3 y coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w9cgueum8no"
   },
   "source": [
    "### Example of a TDOA dataset created through an actual experiment.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1Wym8DdqfQuY4VSDFmxiogRXUl_ade25X' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGKkaEmF_M5q"
   },
   "source": [
    "### Apply random noise to arbitraely generated target data (hat data)\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=15mMsts3LDD5phNdvSHMTWZqrkpJ4FJ8t' width=\"600\">\n",
    "\n",
    "- Based on the interview data, we generated simulation space and $y_{hat}$ data.\n",
    "\n",
    "\n",
    " - We have real experimental data, but since the actual data is already parsed one, we thought that it was not suitable for creating a rough environment. So we decided to proceed with computer simulation.\n",
    "\n",
    "\n",
    " - We finding out the error range of **device** using the product specification of the tag used in the experiment.\n",
    " \n",
    "- Error range was randomly applied similarly to the actual measurement value for simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezsW9WCK_Mkb"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_device_error = 0.1  #위의 사진에 의해 device 기기의 에러값 선언\n",
    "\n",
    "noise_x_list = []\n",
    "noise_y_list = []\n",
    "\n",
    "\n",
    "while(len(noise_x_list) != MC_N):\n",
    "    #After generating a Gaussian standard normal distribution random number from mean 0 stdv 1,\n",
    "    # multiplicate with max_device_error and scaled to the maximum error.\n",
    "    temp_x = np.random.randn()  * max_device_error   \n",
    "    temp_y = np.random.randn()  * max_device_error\n",
    "    \n",
    "    if( (temp_x**2 + temp_y**2 < max_device_error ** 2) ):    \n",
    "        noise_x_list.append(temp_x)\n",
    "        noise_y_list.append(temp_y)\n",
    "    \n",
    "    \n",
    "X_hat_x_list = [x+y for x,y in zip(X_x_list, noise_x_list)]   # X coordinate generated from device\n",
    "X_hat_y_list = [x+y for x,y in zip(X_y_list, noise_y_list)]   # Y coordinate generated from device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8jAI_M8_Uoh"
   },
   "source": [
    "### Create distance between each sensor and hat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv0LR3zY_dAV"
   },
   "outputs": [],
   "source": [
    "distance_ref_X_hat_list = [-100] * MC_N  \n",
    "distance_one_X_hat_list = [-100] * MC_N  \n",
    "distance_two_X_hat_list = [-100] * MC_N  \n",
    "distance_three_X_hat_list = [-100] * MC_N  \n",
    "\n",
    "\n",
    "for i in range(MC_N):\n",
    "    X_x = X_x_list[i]\n",
    "    X_y = X_y_list[i]\n",
    "    \n",
    "    X_hat_x = X_hat_x_list[i]\n",
    "    X_hat_y = X_hat_y_list[i]\n",
    "    \n",
    "    sensor_ref_x = sensor_ref_x_list[i]\n",
    "    sensor_ref_y = sensor_ref_y_list[i]\n",
    "    sensor_one_x = sensor_one_x_list[i]\n",
    "    sensor_one_y = sensor_one_y_list[i]\n",
    "    sensor_two_x = sensor_two_x_list[i]\n",
    "    sensor_two_y = sensor_two_y_list[i]\n",
    "    sensor_three_x = sensor_three_x_list[i]\n",
    "    sensor_three_y = sensor_three_y_list[i]\n",
    "    \n",
    "    \n",
    "    distance_ref_X_hat_list[i] = math.sqrt((X_hat_x - sensor_ref_x)**2 + (X_hat_y - sensor_ref_y)**2)  # ref과 Xhat 거리\n",
    "    distance_one_X_hat_list[i] = math.sqrt((X_hat_x - sensor_one_x)**2 + (X_hat_y - sensor_one_y)**2)  # 1과 Xhat 거리\n",
    "    distance_two_X_hat_list[i] = math.sqrt((X_hat_x - sensor_two_x)**2 + (X_hat_y - sensor_two_y)**2)  # 2와 Xhat 거리\n",
    "    distance_three_X_hat_list[i] = math.sqrt((X_hat_x - sensor_three_x)**2 + (X_hat_y - sensor_three_y)**2)  # 3과 타Xhat 거리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERjxV0VN_lp6"
   },
   "source": [
    "### Apply environmental error\n",
    "\n",
    "+ Several ways to apply environmental error\n",
    "    + 1. Just make 0 for errors [previous idea]\n",
    "    + 2. Make random number for errors\n",
    "    + 3. **Apply new distances using physics formulas for obstacles**\n",
    "\n",
    "\\\n",
    "#### Apply physics fomula for obstacles - [Fresnel Zone]\n",
    "+ The Fresnel area is used to analyze the effect of obstacles placed on the line-of-sight transmission path. \n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TM-d6j_zSnbp1VAGcn32ndew5wSkZ1-h' width=\"500\">\n",
    "\n",
    "+ Assuming there is an obstacle, the error rate is assumed to be 30%. \\\n",
    "\n",
    "+ If there is an obstacle, it is necessary to use a new distance affected by the obstacle rather than the straight distance between the transmitter and the receiver. \\\n",
    "\n",
    "+ Therefore, using Fresnel zone equation, after calculating a new distance, apply to our distance data.\n",
    "\n",
    "#### Fresnel Equation\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TM8A-AtmkyGS50W36La9IpqiyFePRfjd' width=\"300\">\n",
    "\n",
    "+ while lambda is wavelength of electric wave\n",
    "+ $d_1$ is distance between obstacle and transmitter\n",
    "+ $d_2$ is distance between obstacle and receiver\n",
    "\n",
    "So, applied distance result will be:\n",
    "+ $\\sqrt{{d_1}^2 + {A_1}^2} + \\sqrt{{d_2}^2 + {A_1}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRTrOL_3_nFo"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'X_x':X_x_list , 'X_y' : X_y_list , \n",
    "                         'X_noise_x':noise_x_list , 'X_noise_y' : noise_y_list , \n",
    "                          'X_hat_x':X_hat_x_list ,'X_hat_y':X_hat_y_list,\n",
    "                          'distance_ref_X_hat' : distance_ref_X_hat_list , 'distance_one_X_hat' : distance_one_X_hat_list,\n",
    "                          'distance_two_X_hat' : distance_two_X_hat_list , 'distance_three_X_hat' : distance_three_X_hat_list   \n",
    "                         })\n",
    "\n",
    "\n",
    "def create_environment_error(distance):\n",
    "    error_rate = 0.7\n",
    "    if(float(np.random.rand()) < error_rate):\n",
    "        obstacle_heigth =  3 * np.random.rand()   #부딪히는 물체의 길이\n",
    "        if(distance < obstacle_heigth):         # 말이 안되는거 상황 0으로 채워 넣음\n",
    "            return 0\n",
    "        \n",
    "        #By 프레넬 영역을 이용한 추가 이동 거리 구현(함 위에 사이트 읽어보고 이상하다 싶으면 바로 말해줘요)\n",
    "        distance1 = np.random.randn() + (distance/2)\n",
    "        distance2 = distance - distance1\n",
    "        if(distance1 < 0 or distance2 < 0):     # 말이 안되는거 상황 0으로 채워 넣음\n",
    "            return 0 \n",
    "        \n",
    "        Fresnel_a = 0.01 * math.sqrt(distance1 * distance2 / (distance1+distance2))\n",
    "\n",
    "        break_n = 1\n",
    "        while(Fresnel_a < obstacle_heigth):\n",
    "            Fresnel_a = Fresnel_a * (break_n+1) / break_n\n",
    "            break_n +=1\n",
    "        \n",
    "        distance_final = math.sqrt(np.square(distance1) + np.square(Fresnel_a)) + math.sqrt(np.square(distance2) + np.square(Fresnel_a))\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        distance_final = distance\n",
    "\n",
    "    return distance_final\n",
    "\n",
    "df['error_distance_ref_X_hat'] = df['distance_ref_X_hat'].apply(create_environment_error)\n",
    "df['error_distance_one_X_hat'] = df['distance_one_X_hat'].apply(create_environment_error)\n",
    "df['error_distance_two_X_hat'] = df['distance_two_X_hat'].apply(create_environment_error)\n",
    "df['error_distance_three_X_hat'] = df['distance_three_X_hat'].apply(create_environment_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lxZchvvA2y_"
   },
   "source": [
    "### Create TDOA between reference sensor and each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMc5s58zAyof"
   },
   "outputs": [],
   "source": [
    "df['TDOA_X_hat_ref_one_error'] = df['error_distance_ref_X_hat'] - df['error_distance_one_X_hat']\n",
    "df['TDOA_X_hat_ref_two_error'] = df['error_distance_ref_X_hat'] - df['error_distance_two_X_hat']\n",
    "df['TDOA_X_hat_ref_three_error'] = df['error_distance_ref_X_hat'] - df['error_distance_three_X_hat']\n",
    "\n",
    "df_parsing = df[['TDOA_X_hat_ref_one_error' , 'TDOA_X_hat_ref_two_error' , 'TDOA_X_hat_ref_three_error' , 'X_x' , 'X_y']]\n",
    "df_parsing.columns = ['TDOA_1', 'TDOA_2', 'TDOA_3' , 'coordinate_x' , 'coordinate_y']\n",
    "\n",
    "df_parsing = df_parsing.reset_index(drop=True)\n",
    "\n",
    "TDOA_X_ref_one_list = df_parsing['TDOA_1'].tolist()\n",
    "TDOA_X_ref_two_list = df_parsing['TDOA_2'].tolist()\n",
    "TDOA_X_ref_three_list = df_parsing['TDOA_3'].tolist()\n",
    "\n",
    "TDOA_pair_ref = [(TDOA_X_ref_one_list[ii], TDOA_X_ref_two_list[ii], TDOA_X_ref_three_list[ii]) for ii in range(len(TDOA_X_ref_one_list))]\n",
    "\n",
    "ylabel_ref = [(X_x_list[ii] / size_x, X_y_list[ii] / size_y ) for ii in range(len(X_x_list))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5f0hP0FA7ru"
   },
   "source": [
    "### Scaling for data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8XC0eLi71dE"
   },
   "outputs": [],
   "source": [
    "def ScalerCoordinate(value):   #world size = area's width and height , value =  x,y coordinate\n",
    "    world_size = 25\n",
    "    value = value / world_size\n",
    "    return value\n",
    "\n",
    "\n",
    "def ScalerTDOA(value):   #world size = area's width and height , value = TDOA value\n",
    "    #world_size = 25 * 2**(0.5)\n",
    "    world_size = 100  \n",
    "    value = value / world_size\n",
    "    return value\n",
    "\n",
    "\n",
    "df = df_parsing\n",
    "\n",
    "df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']] = df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].apply(ScalerTDOA)  #길이에 대하여 스케일링\n",
    "df[['coordinate_x' , 'coordinate_y']] = df[['coordinate_x' , 'coordinate_y']].apply(ScalerCoordinate)  #좌표에 대하여 스케일링\n",
    "\n",
    "train_df , test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "train_TDOAs = train_df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].to_numpy()\n",
    "train_X_Hats = train_df[['coordinate_x' , 'coordinate_y']].to_numpy()\n",
    "\n",
    "test_TDOAs = test_df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].to_numpy()\n",
    "test_X_Hats = test_df[['coordinate_x' , 'coordinate_y']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRUIUWtdCS5l"
   },
   "source": [
    "### Create TDOA Image from TDOA data\n",
    "\n",
    "+ Reason why we use image data\n",
    "1. Hyperbola is a non-linear equation, and the calculation cost needs to be simplified, not a joke.\n",
    "2. High position uncertainty due to time subtraction operation to make TDOA\n",
    "3. In a very robust environment, the TDOA error value correction algorithm does not work well. To solve this, other methods are needed instead of correcting the values!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Initial Idea:\n",
    "+ Make TDOA image by transform TDOA hyperbola into grid world.\n",
    "+ Each grid contains value of 0 or 1. \n",
    "+ value 1 means TDOA hyperbola passes grid, and 0 is not.\n",
    "\n",
    "\\\n",
    "<img src='https://drive.google.com/uc?id=1TME89PaXmGiGE7kCSiAGq4ohkLRBcJSe' width=\"1000\">\n",
    "\n",
    "#### Modificated idea:\n",
    "An image of the 'probability' that the hyperbolic equation will pass through the grid area\n",
    "\n",
    "+ Make TDOA image by transform TDOA hyperbola into grid world.\n",
    "+ Each grid contains value between 0 and 1. \n",
    "+ Each value means probability that TDOA hyperbola passes grid.\n",
    "+ If grid value is close to 1, it means there are high probability that hyperbola passes.\n",
    "\n",
    "+ If the difference between the TDOA value calculated by the center coordinates of each grid world and the TDOA value of the actual target is very small, we can predict that the target is in the grid world.\n",
    "+ We can gradually decrease the probability by increasing the value of this epsilon.\n",
    "\n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1Hb-TvYikfaonQrfYqtqO5sIEBuuUd--y' width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqb-2NArCTOb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TDOA image 생성 모듈 정의\n",
    "# input: TDPA\n",
    "# output: TDOA_images\n",
    "  \n",
    "def TDOA_image_generation(sensor1, sensor2, TDOA, world_size_x, world_size_y, grid_size, epsilon, probability_gap):\n",
    "   \n",
    "  center_x = np.linspace(0 , world_size_x , int(world_size_x / grid_size))  + 0.5*grid_size  # x길이 10에 그리드사이즈가 2로 가정했을때 해당 좌표의 중심 좌표는 1, 3, 5, 7, 9 => 이를 수학적으로 수열화 한거!\n",
    "  center_y = np.linspace(world_size_y , 0 , int(world_size_x / grid_size))  + 0.5*grid_size  # 마찬가지\n",
    "  cord_center_x, cord_center_y = np.meshgrid(center_x,center_y)  #이를 매트릭스화\n",
    "  \n",
    "  distance_matrix = np.sqrt((cord_center_x - sensor1[0])**2 + (cord_center_y - sensor1[1])**2) - np.sqrt((cord_center_x - sensor2[0])**2 + (cord_center_y - sensor2[1])**2)  # 그리드 사이즈 중심좌표로부터 센서간의 거리의 계산 차 (=중심 좌표의 TDOA)\n",
    "  tdoa_distance = np.abs(distance_matrix - TDOA)  #실제 TDOA 값과 차이 계산\n",
    "\n",
    "  # 예시 [[10.8,0.38]\n",
    "  #        [7.679,12.6479]]\n",
    "\n",
    "  tdoa_image =  tdoa_distance // epsilon  #앱실론의 몇배인지 계산하기 위해서 ex) 앱실론이 0.1 이고 거리차가 0.38이면 0이 되겠죠?\n",
    "  tdoa_image[tdoa_image > probability_gap] = probability_gap  # 너무 차이나는 애들 통일 ex) 앱실론이 0.1이고 거리차가 15든 12이든 밑의 계산을 위해 10(probability)으로 통일\n",
    "  \n",
    "  tdoa_image = (probability_gap - tdoa_image) / probability_gap #( [[10,10]     -   [[10,0]]   ) / 10   =  [[0,1]\n",
    "                                                                #   10,10]]         [7,10]                  [0.3,0]]\n",
    "\n",
    "  return tdoa_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUG3cVBo-c2d",
    "outputId": "b16878da-2e08-40be-ddb0-eaf4cd82e85f"
   },
   "outputs": [],
   "source": [
    "TDOA_images_ref = []\n",
    "for ii in range(len(TDOA_pair_ref)):\n",
    "    image1 = TDOA_image_generation(sensor_ref, sensor1, TDOA_pair_ref[ii][0], world_size_x, world_size_y, grid_size, epsilon, probability_gap)\n",
    "    image2 = TDOA_image_generation(sensor_ref, sensor2, TDOA_pair_ref[ii][1], world_size_x, world_size_y, grid_size, epsilon, probability_gap)\n",
    "    image3 = TDOA_image_generation(sensor_ref, sensor3, TDOA_pair_ref[ii][2], world_size_x, world_size_y, grid_size, epsilon, probability_gap)\n",
    "    TDOA_images_ref.append((image1, image2, image3))\n",
    "    if(len(TDOA_images_ref) % 1000 == 0):\n",
    "      print(len(TDOA_images_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu41V4pfE1ml"
   },
   "source": [
    "  #### Image size\n",
    "\n",
    "- Since Grid_size is 0.25, image size is 100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "157CHVzI-Eke",
    "outputId": "77c178cd-515e-4064-eade-9797a3b1b0c7"
   },
   "outputs": [],
   "source": [
    "TDOA_sample = TDOA_pair_ref[0][0]\n",
    "TDOA_sample_image = TDOA_image_generation(sensor_ref, sensor1, TDOA_sample, world_size_x, world_size_y, grid_size, epsilon, probability_gap)\n",
    "TDOA_sample_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wZgxWIEFGmQ"
   },
   "source": [
    "### Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxZNExOg_KAD"
   },
   "outputs": [],
   "source": [
    "TDOA_images_cnn = TDOA_images_ref\n",
    "ylabels = ylabel_ref\n",
    "\n",
    "TDOA_images_test = TDOA_images_cnn[int(0.8*MC_N):]\n",
    "TDOA_image_val = TDOA_images_cnn[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "TDOA_image_train = TDOA_images_cnn[:int(0.6*MC_N)]\n",
    "\n",
    "ylabels_test = ylabels[int(0.8*MC_N):]\n",
    "ylabels_val = ylabels[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "ylabels_train = ylabels[:int(0.6*MC_N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuK5Z6DXFMT6"
   },
   "source": [
    "### Make model structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn_Ttq6u8Fnu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def cnn_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(CNN1_outchannel, (CNN1_kernal, CNN1_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN1_stride, \n",
    "                            input_shape= (TDOA_sample_image.shape[0],TDOA_sample_image.shape[1], CNN1_inputchannel) ,kernel_initializer='he_normal')) \n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides= (Pool_stride, Pool_stride), padding = \"SAME\"  ) )\n",
    "    model.add(layers.Conv2D(CNN2_outchannel, (CNN2_kernal, CNN2_kernal),  activation=layers.LeakyReLU(alpha=0.01), strides=CNN2_stride ,kernel_initializer='he_normal'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides=  (Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN3_stride ,kernel_initializer='he_normal'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides=  (Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    model.add(layers.Conv2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN3_stride ,kernel_initializer='he_normal')) \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation=None))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySGOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.01, name=\"SGOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._is_first = True\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"pv\") #previous variable i.e. weight or bias\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"pg\") #previous gradient\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        new_var_m = var - grad * lr_t\n",
    "        pv_var = self.get_slot(var, \"pv\")\n",
    "        pg_var = self.get_slot(var, \"pg\")\n",
    "        \n",
    "        if self._is_first:\n",
    "            self._is_first = False\n",
    "            new_var = new_var_m\n",
    "        else:\n",
    "            cond = grad*pg_var >= 0\n",
    "            print(cond)\n",
    "            avg_weights = (pv_var + var)/2.0\n",
    "            new_var = tf.where(cond, new_var_m, avg_weights)\n",
    "        pv_var.assign(var)\n",
    "        pg_var.assign(grad)\n",
    "        var.assign(new_var)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import resource_variable_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.training import optimizer\n",
    "from tensorflow.python.training import training_ops\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "\n",
    "\n",
    "@tf_export(v1=[\"train.AdamOptimizer\"])\n",
    "class AdamOptimizer(optimizer.Optimizer):\n",
    "\n",
    "  def __init__(self,\n",
    "               learning_rate=0.001,\n",
    "               beta1=0.9,\n",
    "               beta2=0.999,\n",
    "               epsilon=1e-8,\n",
    "               use_locking=False,\n",
    "               name=\"Adam\"):\n",
    "\n",
    "    super(AdamOptimizer, self).__init__(use_locking, name)\n",
    "    self._lr = learning_rate\n",
    "    self._beta1 = beta1\n",
    "    self._beta2 = beta2\n",
    "    self._epsilon = epsilon\n",
    "\n",
    "    # Tensor versions of the constructor arguments, created in _prepare().\n",
    "    self._lr_t = None\n",
    "    self._beta1_t = None\n",
    "    self._beta2_t = None\n",
    "    self._epsilon_t = None\n",
    "\n",
    "  def _get_beta_accumulators(self):\n",
    "    with ops.init_scope():\n",
    "      if context.executing_eagerly():\n",
    "        graph = None\n",
    "      else:\n",
    "        graph = ops.get_default_graph()\n",
    "      return (self._get_non_slot_variable(\"beta1_power\", graph=graph),\n",
    "              self._get_non_slot_variable(\"beta2_power\", graph=graph))\n",
    "\n",
    "  def _create_slots(self, var_list):\n",
    "    # Create the beta1 and beta2 accumulators on the same device as the first\n",
    "    # variable. Sort the var_list to make sure this device is consistent across\n",
    "    # workers (these need to go on the same PS, otherwise some updates are\n",
    "    # silently ignored).\n",
    "    first_var = min(var_list, key=lambda x: x.name)\n",
    "    self._create_non_slot_variable(\n",
    "        initial_value=self._beta1, name=\"beta1_power\", colocate_with=first_var)\n",
    "    self._create_non_slot_variable(\n",
    "        initial_value=self._beta2, name=\"beta2_power\", colocate_with=first_var)\n",
    "\n",
    "    # Create slots for the first and second moments.\n",
    "    for v in var_list:\n",
    "      self._zeros_slot(v, \"m\", self._name)\n",
    "      self._zeros_slot(v, \"v\", self._name)\n",
    "\n",
    "  def _prepare(self):\n",
    "    lr = self._call_if_callable(self._lr)\n",
    "    beta1 = self._call_if_callable(self._beta1)\n",
    "    beta2 = self._call_if_callable(self._beta2)\n",
    "    epsilon = self._call_if_callable(self._epsilon)\n",
    "\n",
    "    self._lr_t = ops.convert_to_tensor(lr, name=\"learning_rate\")\n",
    "    self._beta1_t = ops.convert_to_tensor(beta1, name=\"beta1\")\n",
    "    self._beta2_t = ops.convert_to_tensor(beta2, name=\"beta2\")\n",
    "    self._epsilon_t = ops.convert_to_tensor(epsilon, name=\"epsilon\")\n",
    "\n",
    "  def _apply_dense(self, grad, var):\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    return training_ops.apply_adam(\n",
    "        var,\n",
    "        m,\n",
    "        v,\n",
    "        math_ops.cast(beta1_power, var.dtype.base_dtype),\n",
    "        math_ops.cast(beta2_power, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._lr_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta1_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta2_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._epsilon_t, var.dtype.base_dtype),\n",
    "        grad,\n",
    "        use_locking=self._use_locking).op\n",
    "\n",
    "  def _resource_apply_dense(self, grad, var):\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    return training_ops.resource_apply_adam(\n",
    "        var.handle,\n",
    "        m.handle,\n",
    "        v.handle,\n",
    "        math_ops.cast(beta1_power, grad.dtype.base_dtype),\n",
    "        math_ops.cast(beta2_power, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._lr_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta1_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta2_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._epsilon_t, grad.dtype.base_dtype),\n",
    "        grad,\n",
    "        use_locking=self._use_locking)\n",
    "\n",
    "  def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    beta1_power = math_ops.cast(beta1_power, var.dtype.base_dtype)\n",
    "    beta2_power = math_ops.cast(beta2_power, var.dtype.base_dtype)\n",
    "    lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "    beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "    beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "    epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "    lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "    # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    m_scaled_g_values = grad * (1 - beta1_t)\n",
    "    m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)\n",
    "    with ops.control_dependencies([m_t]):\n",
    "      m_t = scatter_add(m, indices, m_scaled_g_values)\n",
    "    # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "    v_t = state_ops.assign(v, v * beta2_t, use_locking=self._use_locking)\n",
    "    with ops.control_dependencies([v_t]):\n",
    "      v_t = scatter_add(v, indices, v_scaled_g_values)\n",
    "    v_sqrt = math_ops.sqrt(v_t)\n",
    "    var_update = state_ops.assign_sub(\n",
    "        var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)\n",
    "    return control_flow_ops.group(*[var_update, m_t, v_t])\n",
    "\n",
    "  def _apply_sparse(self, grad, var):\n",
    "    return self._apply_sparse_shared(\n",
    "        grad.values,\n",
    "        var,\n",
    "        grad.indices,\n",
    "        lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n",
    "            x,\n",
    "            i,\n",
    "            v,\n",
    "            use_locking=self._use_locking))\n",
    "\n",
    "  def _resource_scatter_add(self, x, i, v):\n",
    "    with ops.control_dependencies(\n",
    "        [resource_variable_ops.resource_scatter_add(x.handle, i, v)]):\n",
    "      return x.value()\n",
    "\n",
    "  def _resource_apply_sparse(self, grad, var, indices):\n",
    "    return self._apply_sparse_shared(grad, var, indices,\n",
    "                                     self._resource_scatter_add)\n",
    "\n",
    "  def _finish(self, update_ops, name_scope):\n",
    "    # Update the power accumulators.\n",
    "    with ops.control_dependencies(update_ops):\n",
    "      beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "      with ops.colocate_with(beta1_power):\n",
    "        update_beta1 = beta1_power.assign(\n",
    "            beta1_power * self._beta1_t, use_locking=self._use_locking)\n",
    "        update_beta2 = beta2_power.assign(\n",
    "            beta2_power * self._beta2_t, use_locking=self._use_locking)\n",
    "    return control_flow_ops.group(\n",
    "        *update_ops + [update_beta1, update_beta2], name=name_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NS-j5cH_LsA",
    "outputId": "6fb26c74-feda-4183-ec4c-01409e728603"
   },
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', \n",
    "                              patience=8) \n",
    "\n",
    "model.compile(optimizer=AdamOptimizer(),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "\n",
    "history = model.fit(np.array(TDOA_image_train).swapaxes(1,3), np.array(ylabels_train),\n",
    "                    epochs=num_epochs, batch_size=batch_size,verbose=1,\n",
    "                    validation_data=(np.array(TDOA_image_val).swapaxes(1,3), np.array(ylabels_val)),\n",
    "                     callbacks= [ earlystopping])\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "d3ENPh8GAr3g",
    "outputId": "38b69db1-ce3c-4b2b-d42f-2f95c7e16e10"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"mse\"], label = 'mse')\n",
    "ax0.set(title='mse')\n",
    "ax1.plot(hist.history[\"loss\"], label = 'loss')\n",
    "ax1.set(title='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"val_mse\"], label = 'val_mse')\n",
    "ax0.set(title='val mse')\n",
    "ax1.plot(hist.history[\"val_loss\"], label = 'loss')\n",
    "ax1.set(title='val loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI7uaWXeA1uV",
    "outputId": "735361d0-d494-4623-b5b1-5159e6900353"
   },
   "outputs": [],
   "source": [
    "predict_X_Hats = model.predict(np.array(TDOA_images_test).swapaxes(1,3))\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*25 - np.array(ylabels_test)*25), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vb90DJsEaJkU"
   },
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO_q5jfKJgpA"
   },
   "source": [
    "\n",
    "  <img src='https://drive.google.com/uc?id=1TRRt2YHofQiDwstmSEIkLiWsmK2EKut5' width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "model.compile(optimizer=MySGOptimizer(),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "\n",
    "history = model.fit(np.array(TDOA_image_train).swapaxes(1,3), np.array(ylabels_train),\n",
    "                    epochs=num_epochs, batch_size=batch_size,verbose=1,\n",
    "                    validation_data=(np.array(TDOA_image_val).swapaxes(1,3), np.array(ylabels_val)),\n",
    "                     callbacks= [ earlystopping])\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"mse\"], label = 'mse')\n",
    "ax0.set(title='mse')\n",
    "ax1.plot(hist.history[\"loss\"], label = 'loss')\n",
    "ax1.set(title='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"val_mse\"], label = 'val_mse')\n",
    "ax0.set(title='val mse')\n",
    "ax1.plot(hist.history[\"val_loss\"], label = 'loss')\n",
    "ax1.set(title='val loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_X_Hats = model.predict(np.array(TDOA_images_test).swapaxes(1,3))\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*25 - np.array(ylabels_test)*25), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHI0pSSEFPgi"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPagPq8AYpJZ"
   },
   "source": [
    "### 1. Grid size really matters. \n",
    "\n",
    "The smaller the grid size, the more data for model input become more complex but the result is better. (Tradeoff between computational time and error)\n",
    "\n",
    "< For grid_size = 1>\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TOz4y_V3nlOJZOyQVXCMRR7hfQhtSV-J' width=\"350\">\n",
    "\n",
    "< For grid_size = 0.5>\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TPEyYMEnw373MX247bg8uNxfVx038zNt' width=\"300\">\n",
    "\n",
    "\n",
    "### 2. Probability_gap and Epsilon must change relation to Grid size \n",
    "\n",
    "If the value grid size changes, the hyperparameters must be modified accordingly.In the process, the following facts were additionally discovered.\n",
    "\n",
    "\n",
    "\n",
    "*   The probability gap is not unconditionally good because it is large unlike the grid size.\n",
    "*   Most of the epsilon values showed good performance when values slightly smaller than (gridsize / probability_gap * 2).\n",
    "\n",
    "\n",
    "\n",
    "### 3. Comparing with reference paper [Nitsoo et al., 2018]\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TPrf8VJXT4FzvFmAspuF8G5nIhLNfFix' width=\"600\">\n",
    "\n",
    "\n",
    "  <img src='https://drive.google.com/uc?id=1TQu6JWMw4gs6nN97aX13zp1oFusLRFN_' width=\"600\">\n",
    "\n",
    "  In our reference paper, coverage area is 13m x 20m, \n",
    "  \\\n",
    "   MAE is 0.3m~0.8m by various algorithms.\n",
    "\n",
    "  Our coverage area is 25m x 25m and MAE for CNN model is 0.4m\n",
    "  \\\n",
    "  If we consider large coverage area compare and error rate, our result is quite **meaningful** even considering that the environment is a little different.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi94XIOB5K3q"
   },
   "source": [
    "\n",
    "## 3. FCNN (Fully connected Neural Network) Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LLIxw-t2o2V",
    "outputId": "82a94f82-93a8-42ff-e7af-f18fe73b2749"
   },
   "outputs": [],
   "source": [
    "# Do not modify this block\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(25, activation='relu', input_shape=(3,)))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(2))\n",
    "model2.compile(optimizer=AdamOptimizer(), loss='mse', metrics=['mse'])\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "history = model2.fit(train_TDOAs, \n",
    "                      train_X_Hats,\n",
    "                      epochs=num_epochs,\n",
    "                      batch_size=batch_size, \n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "kFoQ-m0l2rA1",
    "outputId": "842069f6-7b8b-45be-be0e-f24bb5690a72"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"mse\"], label = 'mse')\n",
    "ax0.set(title='mae')\n",
    "ax1.plot(hist.history[\"loss\"], label = 'loss')\n",
    "ax1.set(title='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-8HBjlw2tL_",
    "outputId": "fd65eadb-8372-4aab-a5f6-9eee511b5b3c"
   },
   "outputs": [],
   "source": [
    "predict_X_Hats = model2.predict(test_TDOAs)\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*25 - test_X_Hats*25), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yng1gkjBVlNB",
    "outputId": "66139d00-7704-40c6-c9c3-e08719d6a7af"
   },
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(25, activation='relu', input_shape=(3,)))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(2))\n",
    "model2.compile(optimizer=AdamOptimizer(), loss='mse', metrics=['mse'])\n",
    "\n",
    "model2.compile(optimizer=MySGOptimizer(), loss='mse', metrics=['mse'])\n",
    "\n",
    "num_epochs = 6\n",
    "\n",
    "history = model2.fit(train_TDOAs, \n",
    "                      train_X_Hats,\n",
    "                      epochs=num_epochs,\n",
    "                      batch_size=batch_size, \n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history\n",
    "fig,(ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, sharey = False)\n",
    "ax0.plot(hist.history[\"mse\"], label = 'mse')\n",
    "ax0.set(title='mae')\n",
    "ax1.plot(hist.history[\"loss\"], label = 'loss')\n",
    "ax1.set(title='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_X_Hats = model2.predict(test_TDOAs)\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*25 - test_X_Hats*25), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKQ3okmw2q1-"
   },
   "source": [
    "Compare with simple FCNN model, its result is quite acceptable.\n",
    "It needs less computational resource but its difference of error is quite low.\n",
    "\n",
    "However, we need to think about error term. We applied Fresnel equation only 1 time for 30% ratio. In **real world**, it is not. It has **much more obstacles and effect of electric wave of obstacles are much more complicated**. So in this environment that has only 1 obstacles, its differences are not significant, but if we apply more complicated world, **CNN will show better result**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvQwyqBVPE5u"
   },
   "source": [
    "## 4. Real life application\n",
    "\n",
    "In introduction, we used Amazon Go as an example. However, Amazon go needs very low error of target tracking. 0.4M error is not applicable for Amazon go case. So we thought about other applications for this location tracking.\n",
    "\n",
    "\\\n",
    "#### **1. Indoor Navigation**\n",
    "\n",
    "For finding indoor route, some errors are acceptable. \n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TRHqa9oD8qeV2Lv8-EFdkPoz-_GZS7Vf' width=\"200\">\n",
    "\n",
    "#### **2. Gym tracking**\n",
    "\n",
    "When you exercise, you can record what kind of exercise you did for how many minutes by synchronizing it with location information without having to record it separately.\n",
    "\n",
    "\\\n",
    "#### **3. Location tracking in emergency.**\n",
    "\n",
    "It can be usefully used in case of emergency such as fire. It can help rescue people by figuring out the target location in a situation where visibility is not secured.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TRIrHuMJrICivTVj7JruFnJiFO2iiiWX' width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7Vp2lolhRDP"
   },
   "source": [
    "## 5. Future Research \n",
    "\n",
    "**Mask Generation** : Although deep learning model can learn the value of mask by itself through analyzing correlation of TDOA measurements, we simply adopt the fixed value of mask, and more studies will be conducted in our future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C98NllegUu3n"
   },
   "source": [
    "# References\n",
    "\n",
    "1. NIITSOO, Arne; EDELHÄUΒER, Thorsten; MUTSCHLER, Christopher. Convolutional neural networks for position estimation in tdoa-based locating systems. In: 2018 International Conference on Indoor Positioning and Indoor Navigation (IPIN). IEEE, 2018. p. 1-8.\n",
    "\n",
    "2. XUE, Yuan, et al. DeepTAL: Deep learning for TDOA-based asynchronous localization security with measurement error and missing data. IEEE Access, 2019, 7: 122492-122502.\n",
    "\n",
    "3. J. Baek, J. Lee, Y. Han, H. Shim, and S. Im, “Grid-based target\n",
    "estimation scheme for passive coherent location system,” in 2019 IEEE\n",
    "90th Vehicular Technology Conference (VTC2019-Fall), 2019, pp. 1–5.\n",
    "\n",
    "4. Baek, J., Lee, S., Lee, C., & Park, S. (2021, October). A Deep Learning Approach for Robust Target Tracking in a Cluttered Environment. In 2021 International Conference on Information and Communication Technology Convergence (ICTC) (pp. 1033-1035). IEEE.\n",
    "\n",
    "5. http://preview.kyobobook.co.kr/epubPreviewPopup.jsp?type=web&barcode=480D130703480&search=Y\n",
    "\n",
    "6. https://hyoukjang.github.io/vr/indoor-positioning/ips/2017/10/22/positional-tracking-101-2.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TDOA_present_[3].ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5a905c007ff2d38bb2c7b3a29a7607fb69ad0b0424e092736524db498399bd8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('position31')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
