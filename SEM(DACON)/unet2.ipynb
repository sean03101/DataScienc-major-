{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from cv2 import imread, normalize, resize\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_list = ['Case_1', 'Case_2','Case_3','Case_4']\n",
    "Y_image = []\n",
    "X_image = []\n",
    "\n",
    "for case in case_list:\n",
    "    path = 'C:/Users/user/Desktop/sem/simulation_data/SEM/' +  case # 폴더 경로\n",
    "    folder_list = ['/80','/81','/82','/83','/84']\n",
    "\n",
    "\n",
    "    for folder_name in folder_list:\n",
    "        temp_path = path + folder_name\n",
    "        os.chdir(temp_path) # 해당 폴더로 이동\n",
    "        files = os.listdir(temp_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        for file in files:\n",
    "            if 'itr0' in file:\n",
    "                f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "                image = f / 255\n",
    "                X_image.append(image)\n",
    "    \n",
    "    path = 'C:/Users/user/Desktop/sem/simulation_data/Depth/' +  case # 폴더 경로\n",
    "    for folder_name in folder_list:\n",
    "        temp_path = path + folder_name\n",
    "        os.chdir(temp_path) # 해당 폴더로 이동\n",
    "        files = os.listdir(temp_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        for file in files:\n",
    "            f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = f / 255\n",
    "            Y_image.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in case_list:\n",
    "    path = 'C:/Users/user/Desktop/sem/simulation_data/SEM/' +  case # 폴더 경로\n",
    "    folder_list = ['/80','/81','/82','/83','/84']\n",
    "\n",
    "\n",
    "    for folder_name in folder_list:\n",
    "        temp_path = path + folder_name\n",
    "        os.chdir(temp_path) # 해당 폴더로 이동\n",
    "        files = os.listdir(temp_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        for file in files:\n",
    "            if 'itr1' in file:\n",
    "                f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "                image = f / 255\n",
    "                X_image.append(image)\n",
    "    \n",
    "    path = 'C:/Users/user/Desktop/sem/simulation_data/Depth/' +  case # 폴더 경로\n",
    "    for folder_name in folder_list:\n",
    "        temp_path = path + folder_name\n",
    "        os.chdir(temp_path) # 해당 폴더로 이동\n",
    "        files = os.listdir(temp_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        for file in files:\n",
    "            f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = f / 255\n",
    "            Y_image.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file_name_list = []\n",
    "depth_avg_list = []\n",
    "\n",
    "with open('C:/Users/user/Desktop/sem/train/average_depth.csv', 'r') as file:\n",
    "    file_read = csv.reader(file)\n",
    "    for line in file:\n",
    "        new_line = line.replace(\"\\n\", \"\")\n",
    "        new_line2 = new_line.split(',')\n",
    "        file_name_list.append(new_line2[0])\t\n",
    "        depth_avg_list.append(new_line2[1])\n",
    "        \n",
    "del file_name_list[0]\n",
    "del depth_avg_list[0]\n",
    "\n",
    "depth_list = ['Depth_110', 'Depth_120','Depth_130','Depth_140']\n",
    "\n",
    "for depht in depth_list:\n",
    "    path = 'C:/Users/user/Desktop/sem/train/SEM/' +  depht # 폴더 경로\n",
    "    folder_list = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "\n",
    "\n",
    "    for folder_name in folder_list:\n",
    "        temp_path = path + '/' + folder_name\n",
    "        os.chdir(temp_path) # 해당 폴더로 이동\n",
    "        files = os.listdir(temp_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        temp_y_name = depht.lower() + '_' + folder_name\n",
    "        \n",
    "        for file in files:\n",
    "            f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = f / 255\n",
    "            X_image.append(image)\n",
    "            \n",
    "            avg_depth = float(depth_avg_list[int(file_name_list.index(temp_y_name))])\n",
    "            Y_image_temp = np.ones(shape=(f.shape[0],f.shape[1]), dtype=np.float64)\n",
    "            Y_image.append(Y_image_temp * (avg_depth / 255))\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = np.expand_dims(X_image, axis=-1)\n",
    "X_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_image = np.expand_dims(Y_image, axis=-1)\n",
    "Y_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_image[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_image[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train1, x_test, y_train1, y_test = train_test_split(X_image, Y_image, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train,dtype=np.float64)\n",
    "y_train = np.array(y_train,dtype=np.float64)\n",
    "\n",
    "x_val = np.array(x_val,dtype=np.float64)\n",
    "y_val = np.array(y_val,dtype=np.float64)\n",
    "\n",
    "x_test = np.array(x_test,dtype=np.float64)\n",
    "y_test = np.array(y_test,dtype=np.float64)\n",
    "\n",
    "path = 'C:/Users/user/Desktop/sem'\n",
    "os.chdir(path)\n",
    "\n",
    "checkpoint_path = \"C:/Users/user/Desktop/sem/weight/unet/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_freq='epoch',  monitor='val_loss', verbose=1, mode=\"min\")\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                              patience=9)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, verbose=1, mode=\"min\",\n",
    "                              patience=7, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def my_mse(y_true, y_pred):\n",
    "    #difference between true label and predicted label\n",
    "    \n",
    "    if float(y_true[0][0][0]) <= 1:\n",
    "        mean_sqr_error = K.mean(K.square(y_pred - y_true))\n",
    "        \n",
    "    else:\n",
    "        y_pred_avg= K.mean(y_pred) \n",
    "        y_true_avg = float(y_true[0][0][0]) / 255\n",
    "        mean_sqr_error = K.square(y_true_avg-y_pred_avg)\n",
    "        \n",
    "    return mean_sqr_error\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models\n",
    "\n",
    "model = models.unet_plus_2d((f.shape[0],f.shape[1],1), [32, 64, 128, 512], n_labels= 1, output_activation=None, batch_norm=True, deep_supervision=True)\n",
    "\n",
    "\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=1 * 1e-4))\n",
    "history = model.fit(x_train, y_train, \n",
    "                         validation_data=(x_val, y_val),\n",
    "                         epochs=50, batch_size = 64,\n",
    "                         callbacks= [ earlystopping, reduce_lr, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model__hist(hist):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    #plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models\n",
    "\n",
    "max_point = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\txnet_output_sup0\n",
      "\txnet_output_sup1\n",
      "\txnet_output_sup2\n",
      "\txnet_output_final\n"
     ]
    }
   ],
   "source": [
    "model = models.unet_plus_2d((72,48,1), [32, 64, 128, 512], n_labels= 1, output_activation=None, batch_norm=True, deep_supervision=True)\n",
    "#val_loss_history = history.history[\"val_loss\"]\n",
    "#max_point = val_loss_history.index(min(val_loss_history))\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1 * 1e-4),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "if max_point > 8:\n",
    "    model.load_weights(\n",
    "        \"C:/Users/user/Desktop/sem/weight/unet/cp-\" + str(max_point+1) + \".ckpt\"\n",
    "    )\n",
    "else:\n",
    "    model.load_weights(\n",
    "        \"C:/Users/user/Desktop/sem/weight/unet/cp-0\" + str(max_point+1) + \".ckpt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(x_val, y_val)\n",
    "\n",
    "#plot_model__hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_images = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_gap = decoded_images*255 - y_test*255\n",
    "distance_gap_new = distance_gap.reshape(y_test.shape[0],-1)\n",
    "\n",
    "avg_depth = np.mean(distance_gap_new,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(avg_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(avg_depth)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5)\n",
    "fig.set_size_inches(12, 6)\n",
    "for i in range(15):\n",
    "    axes[i//5, i%5].imshow(y_test[i]*255, cmap='gray')\n",
    "    axes[i//5, i%5].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Original Images')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(3, 5)\n",
    "fig.set_size_inches(12, 6)\n",
    "for i in range(15):\n",
    "    axes[i//5, i%5].imshow(decoded_images[i]*255, cmap='gray')\n",
    "    axes[i//5, i%5].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Auto Encoder Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/user/Desktop/sem/test/SEM' # 폴더 경로\n",
    "\n",
    "test_image = []\n",
    "\n",
    "\n",
    "os.chdir(path) # 해당 폴더로 이동\n",
    "files = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "    \n",
    "for file in files:\n",
    "    f = imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    image = f / 255\n",
    "    test_image.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwer = np.expand_dims(image, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer xnet_model: expected shape=(None, 72, 48, 1), found shape=(None, 48, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\sem\\unet2.ipynb 셀 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sem/unet2.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m decoded_images \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray(qwer, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64))\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1727\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1726\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1727\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   1728\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1729\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    934\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    761\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    762\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    764\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    767\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3050\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 3050\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   3051\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3440\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3444\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   3445\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[0;32m   3447\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3274\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   3275\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3276\u001b[0m ]\n\u001b[0;32m   3277\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   3278\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   3280\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   3281\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   3282\u001b[0m         args,\n\u001b[0;32m   3283\u001b[0m         kwargs,\n\u001b[0;32m   3284\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   3285\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   3286\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   3287\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   3288\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[0;32m   3289\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   3290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   3291\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   3292\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3293\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3294\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3295\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3296\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3297\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 999\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1001\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1004\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    669\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    670\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 672\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    673\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    985\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 986\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    987\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    988\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\Users\\user\\.conda\\envs\\position31\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer xnet_model: expected shape=(None, 72, 48, 1), found shape=(None, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "decoded_images = model.predict(np.array(qwer, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5)\n",
    "fig.set_size_inches(12, 6)\n",
    "for i in range(15):\n",
    "    axes[i//5, i%5].imshow(test_image[i]*255, cmap='gray')\n",
    "    axes[i//5, i%5].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('SEM Images')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(3, 5)\n",
    "fig.set_size_inches(12, 6)\n",
    "for i in range(15):\n",
    "    axes[i//5, i%5].imshow(decoded_images[i]*255, cmap='gray')\n",
    "    axes[i//5, i%5].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.title('Auto Encoder Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def inference(decoded_images, files):\n",
    "        \n",
    "    os.makedirs('../../submission', exist_ok=True)\n",
    "    os.chdir(\"../../submission\")\n",
    "    sub_imgs = []\n",
    "    \n",
    "    for path, pred_img in zip(files, decoded_images):\n",
    "        cv2.imwrite(path, pred_img*255)\n",
    "        sub_imgs.append(path)\n",
    "        \n",
    "    submission = zipfile.ZipFile(\"../submission.zip\", 'w')\n",
    "    for path in sub_imgs:\n",
    "        submission.write(path)\n",
    "    submission.close()\n",
    "    \n",
    "inference(decoded_images, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grayImg = cv2.imread('C:/Users/user/Desktop/sem/submission/000000.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(grayImg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\sem\\unet2.ipynb 셀 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sem/unet2.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(decoded_images[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sem/unet2.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(decoded_images[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('position31')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a905c007ff2d38bb2c7b3a29a7607fb69ad0b0424e092736524db498399bd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
